"""
è¶…é«˜è´¨é‡å¹³è¡¡rl_classæ•°æ®é›†ç”Ÿæˆå™¨
- ç›®æ ‡ï¼šæµ‹è¯•é›†è´¨é‡â‰¥90%ï¼Œä½†ä¿æŒåˆç†çš„æ•°æ®é‡
- ç­–ç•¥ï¼šé€‚åº¦åˆ é™¤ï¼Œä¿è¯ç±»åˆ«å¹³è¡¡
- ç›®æ ‡æ•°æ®é‡ï¼šè‡³å°‘500ä¸ªæ ·æœ¬
"""

import pandas as pd
import numpy as np
import os
from data_quality_filter import DataQualityFilter
from data_splitter import DataSplitter
import json


def create_balanced_ultra_high_quality_rl():
    """
    å¹³è¡¡ç­–ç•¥ï¼šä¿è¯è´¨é‡çš„åŒæ—¶ç»´æŒè¶³å¤Ÿçš„æ•°æ®é‡
    """
    print(f"ğŸ¯ å¹³è¡¡ç‰ˆè¶…é«˜è´¨é‡rl_classæ•°æ®é›†ç”Ÿæˆå™¨")
    print("=" * 60)
    print("ğŸ”¥ ç­–ç•¥ï¼šè´¨é‡ä¼˜å…ˆï¼Œæ•°é‡å…¼é¡¾")
    print("ğŸ¯ ç›®æ ‡ï¼šæµ‹è¯•é›†è´¨é‡â‰¥90%ï¼Œæ€»æ ·æœ¬â‰¥500ä¸ª")
    print("âš–ï¸ é‡ç‚¹ï¼šä¿æŒç±»åˆ«å¹³è¡¡")
    
    dataset_name = 'rl_class'
    original_dataset_path = f"datasets/{dataset_name}"
    
    if not os.path.exists(original_dataset_path):
        print(f"âŒ åŸå§‹æ•°æ®é›†ä¸å­˜åœ¨: {original_dataset_path}")
        return False
    
    try:
        # åŠ è½½åŸå§‹æ•°æ®
        print(f"\nğŸ“¥ åŠ è½½åŸå§‹æ•°æ®...")
        X_complete_original = pd.read_pickle(f"{original_dataset_path}/X_complete.pkl")
        y_complete_original = pd.read_pickle(f"{original_dataset_path}/y_complete.pkl")
        
        print(f"   åŸå§‹æ•°æ®: {X_complete_original.shape[0]} æ ·æœ¬")
        original_dist = pd.Series(y_complete_original).value_counts().sort_index()
        print(f"   åŸå§‹åˆ†å¸ƒ: {original_dist.to_dict()}")
        
        # å¤åˆ¶æ•°æ®
        X_complete = X_complete_original.copy()
        y_complete = y_complete_original.copy()
        
        # åˆ†å‰²æ•°æ®
        print(f"\nğŸ”§ åˆ†å‰²æ•°æ®...")
        splitter = DataSplitter(test_size=0.3, random_state=42)
        X_train, X_test, y_train, y_test = splitter.split_dataset(X_complete, y_complete)
        
        print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
        
        # === å¹³è¡¡ç­›é€‰ç­–ç•¥ ===
        def balanced_quality_filter(X_data, y_data, target_quality=0.90, target_samples_per_class=100):
            """å¹³è¡¡çš„è´¨é‡ç­›é€‰ï¼šæ¯ä¸ªç±»åˆ«ä¿ç•™ç›¸åŒæ•°é‡çš„é«˜è´¨é‡æ ·æœ¬"""
            print(f"   ğŸ¯ ç›®æ ‡è´¨é‡: â‰¥{target_quality:.0%}")
            print(f"   ğŸ“Š ç›®æ ‡: æ¯ç±»{target_samples_per_class}ä¸ªæ ·æœ¬")
            
            # é«˜ç²¾åº¦è´¨é‡è¯„ä¼°
            quality_filter = DataQualityFilter(cv_folds=5, n_components=15, random_state=42)
            quality_filter.fit(X_data, y_data, use_feature_selection=True, top_features_ratio=0.8)
            sample_scores = quality_filter.get_sample_scores()
            
            print(f"   å½“å‰å¹³å‡è´¨é‡: {sample_scores['quality_score'].mean():.4f}")
            
            # æŒ‰ç±»åˆ«åˆ†ç»„å¤„ç†
            selected_indices = []
            class_stats = {}
            
            for class_label in sorted(y_data.unique()):
                print(f"\n   ğŸ” å¤„ç†ç±»åˆ« {class_label}:")
                
                # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰æ ·æœ¬
                class_mask = (y_data == class_label)
                class_indices = y_data[class_mask].index.tolist()
                
                # å°†class_indicesæ˜ å°„åˆ°sample_scoresçš„ç´¢å¼•ç©ºé—´
                # sample_scoresçš„sample_idxå­—æ®µå¯¹åº”çš„æ˜¯åœ¨åŸå§‹æ•°æ®ä¸­çš„ç›¸å¯¹ä½ç½®
                valid_sample_indices = []
                for idx in class_indices:
                    # æ‰¾åˆ°è¿™ä¸ªç´¢å¼•åœ¨sample_scoresä¸­å¯¹åº”çš„è¡Œ
                    matching_rows = sample_scores[sample_scores['sample_idx'] == idx]
                    if not matching_rows.empty:
                        valid_sample_indices.extend(matching_rows.index.tolist())
                
                class_scores = sample_scores.loc[valid_sample_indices]
                
                print(f"      æ€»æ ·æœ¬: {len(class_indices)}")
                print(f"      è´¨é‡èŒƒå›´: {class_scores['quality_score'].min():.4f} - {class_scores['quality_score'].max():.4f}")
                print(f"      å¹³å‡è´¨é‡: {class_scores['quality_score'].mean():.4f}")
                
                # æŒ‰è´¨é‡æ’åº
                class_scores_sorted = class_scores.sort_values('quality_score', ascending=False)
                
                # å°è¯•ä¸åŒçš„é€‰æ‹©ç­–ç•¥
                best_selection = None
                best_quality = 0
                
                # ç­–ç•¥1: é€‰æ‹©æœ€é«˜è´¨é‡çš„Nä¸ªæ ·æœ¬
                for n_samples in [target_samples_per_class, target_samples_per_class//2, target_samples_per_class//3]:
                    if n_samples > len(class_scores_sorted):
                        continue
                        
                    top_samples = class_scores_sorted.head(n_samples)
                    avg_quality = top_samples['quality_score'].mean()
                    
                    print(f"      å°è¯•é€‰æ‹©{n_samples}ä¸ª: å¹³å‡è´¨é‡{avg_quality:.4f}")
                    
                    if avg_quality >= target_quality or n_samples == target_samples_per_class//3:
                        best_selection = top_samples
                        best_quality = avg_quality
                        break
                
                # ç­–ç•¥2: å¦‚æœè´¨é‡è¾¾ä¸åˆ°è¦æ±‚ï¼Œé™ä½é˜ˆå€¼ä½†ä¿è¯æ•°é‡
                if best_selection is None or len(best_selection) < target_samples_per_class//3:
                    print(f"      ä½¿ç”¨ä¿åº•ç­–ç•¥ï¼šé€‰æ‹©è´¨é‡æœ€é«˜çš„{min(target_samples_per_class//2, len(class_scores_sorted))}ä¸ª")
                    best_selection = class_scores_sorted.head(min(target_samples_per_class//2, len(class_scores_sorted)))
                    best_quality = best_selection['quality_score'].mean()
                
                # è®°å½•é€‰æ‹©ç»“æœ - éœ€è¦è½¬æ¢å›åŸå§‹çš„y_dataç´¢å¼•
                selected_score_indices = best_selection.index.tolist()
                # ä»è¿™äº›scoreç´¢å¼•æ‰¾åˆ°å¯¹åº”çš„åŸå§‹sample_idx
                original_indices = []
                for score_idx in selected_score_indices:
                    sample_idx = sample_scores.loc[score_idx, 'sample_idx']
                    original_indices.append(sample_idx)
                
                selected_indices.extend(original_indices)
                
                class_stats[class_label] = {
                    'selected_count': len(original_indices),
                    'average_quality': best_quality,
                    'min_quality': best_selection['quality_score'].min(),
                    'max_quality': best_selection['quality_score'].max()
                }
                
                print(f"      âœ… æœ€ç»ˆé€‰æ‹©: {len(original_indices)}ä¸ªæ ·æœ¬")
                print(f"      ğŸ“ˆ é€‰æ‹©è´¨é‡: {best_quality:.4f} ({best_quality*100:.1f}%)")
            
            # ç”Ÿæˆç­›é€‰åçš„æ•°æ®
            X_filtered = X_data.loc[selected_indices].reset_index(drop=True)
            y_filtered = y_data.loc[selected_indices].reset_index(drop=True)
            
            # è®¡ç®—æ€»ä½“è´¨é‡ - éœ€è¦æ‰¾åˆ°selected_indiceså¯¹åº”çš„sample_scoresè¡Œ
            selected_quality_scores = []
            for idx in selected_indices:
                matching_rows = sample_scores[sample_scores['sample_idx'] == idx]
                if not matching_rows.empty:
                    selected_quality_scores.append(matching_rows.iloc[0]['quality_score'])
            
            overall_quality = np.mean(selected_quality_scores) if selected_quality_scores else 0
            
            print(f"\n   ğŸ“Š ç±»åˆ«å¹³è¡¡ç»“æœ:")
            final_dist = pd.Series(y_filtered).value_counts().sort_index()
            for class_label, count in final_dist.items():
                stats = class_stats[class_label]
                print(f"      ç±»åˆ« {class_label}: {count}ä¸ªæ ·æœ¬, è´¨é‡{stats['average_quality']:.4f}")
            
            print(f"   ğŸ’€ åˆ é™¤ç»“æœ:")
            print(f"      åˆ é™¤å‰: {len(X_data)} æ ·æœ¬")
            print(f"      åˆ é™¤å: {len(X_filtered)} æ ·æœ¬")
            print(f"      åˆ é™¤äº†: {len(X_data) - len(X_filtered)} æ ·æœ¬ ({(len(X_data) - len(X_filtered))/len(X_data)*100:.1f}%)")
            print(f"      æ•´ä½“è´¨é‡: {overall_quality:.4f} ({overall_quality*100:.1f}%)")
            
            return X_filtered, y_filtered, overall_quality, class_stats
        
        # å¯¹æµ‹è¯•é›†è¿›è¡Œå¹³è¡¡ç­›é€‰ (è¦æ±‚æ›´é«˜è´¨é‡)
        print(f"\nğŸ’€ æµ‹è¯•é›†å¹³è¡¡ç­›é€‰ (é«˜è´¨é‡è¦æ±‚):")
        X_test_final, y_test_final, test_quality, test_stats = balanced_quality_filter(
            X_test, y_test, target_quality=0.90, target_samples_per_class=80
        )
        
        # å¯¹è®­ç»ƒé›†è¿›è¡Œå¹³è¡¡ç­›é€‰ (ä¿è¯æ•°é‡)
        print(f"\nğŸ”§ è®­ç»ƒé›†å¹³è¡¡ç­›é€‰ (ä¿è¯æ•°é‡):")
        X_train_final, y_train_final, train_quality, train_stats = balanced_quality_filter(
            X_train, y_train, target_quality=0.85, target_samples_per_class=200
        )
        
        # === æ£€æŸ¥ç»“æœ ===
        print(f"\nğŸ“Š æœ€ç»ˆç»“æœç»Ÿè®¡:")
        print(f"   è®­ç»ƒé›†: {X_train.shape[0]} â†’ {X_train_final.shape[0]} (åˆ é™¤{X_train.shape[0]-X_train_final.shape[0]}ä¸ª)")
        print(f"   æµ‹è¯•é›†: {X_test.shape[0]} â†’ {X_test_final.shape[0]} (åˆ é™¤{X_test.shape[0]-X_test_final.shape[0]}ä¸ª)")
        print(f"   è®­ç»ƒé›†è´¨é‡: {train_quality:.4f} ({train_quality*100:.1f}%)")
        print(f"   æµ‹è¯•é›†è´¨é‡: {test_quality:.4f} ({test_quality*100:.1f}%)")
        
        # æ£€æŸ¥ç›®æ ‡è¾¾æˆæƒ…å†µ
        test_target_met = test_quality >= 0.90
        total_samples = len(X_train_final) + len(X_test_final)
        quantity_target_met = total_samples >= 500
        
        print(f"\nğŸ¯ ç›®æ ‡è¾¾æˆæ£€æŸ¥:")
        print(f"   æµ‹è¯•é›†è´¨é‡â‰¥90%: {'âœ…' if test_target_met else 'âŒ'} ({test_quality*100:.1f}%)")
        print(f"   æ€»æ ·æœ¬â‰¥500ä¸ª: {'âœ…' if quantity_target_met else 'âŒ'} ({total_samples}ä¸ª)")
        
        # åˆå¹¶æ•°æ®
        X_complete_balanced = pd.concat([X_train_final, X_test_final], ignore_index=True)
        y_complete_balanced = pd.concat([y_train_final, y_test_final], ignore_index=True)
        
        final_dist = pd.Series(y_complete_balanced).value_counts().sort_index()
        total_retention = len(X_complete_balanced) / len(X_complete_original) * 100
        
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"   åŸå§‹æ ·æœ¬: {len(X_complete_original)}")
        print(f"   æœ€ç»ˆæ ·æœ¬: {len(X_complete_balanced)} (ä¿ç•™{total_retention:.1f}%)")
        print(f"   åˆ é™¤æ ·æœ¬: {len(X_complete_original) - len(X_complete_balanced)} (åˆ é™¤{100-total_retention:.1f}%)")
        print(f"   æœ€ç»ˆåˆ†å¸ƒ: {final_dist.to_dict()}")
        
        # æ£€æŸ¥ç±»åˆ«å¹³è¡¡
        if len(final_dist) >= 2:
            balance_ratio = max(final_dist) / min(final_dist)
            print(f"   ç±»åˆ«å¹³è¡¡: {balance_ratio:.2f}:1 ({'âœ…å¹³è¡¡' if balance_ratio <= 3.0 else 'âŒä¸å¹³è¡¡'})")
        
        # ä¿å­˜å¹³è¡¡çš„è¶…é«˜è´¨é‡æ•°æ®é›†
        print(f"\nğŸ’¾ ä¿å­˜å¹³è¡¡çš„è¶…é«˜è´¨é‡æ•°æ®é›†...")
        
        filtered_dataset_name = "rl_class_balanced_ultra_quality"
        filtered_dataset_path = f"datasets/{filtered_dataset_name}"
        os.makedirs(filtered_dataset_path, exist_ok=True)
        
        # ä¿å­˜æ•°æ®
        X_complete_balanced.to_pickle(f"{filtered_dataset_path}/X_balanced_ultra.pkl")
        y_complete_balanced.to_pickle(f"{filtered_dataset_path}/y_balanced_ultra.pkl")
        
        # ä¿å­˜è¯¦ç»†ä¿¡æ¯
        dataset_info = {
            'dataset_name': filtered_dataset_name,
            'original_dataset': dataset_name,
            'generation_method': 'balanced_ultra_quality_filtering',
            'strategy': 'quality_first_quantity_balanced',
            'targets': {
                'test_quality_target': 0.90,
                'min_total_samples': 500,
                'balance_ratio_max': 3.0
            },
            'results': {
                'original_samples': int(len(X_complete_original)),
                'final_samples': int(len(X_complete_balanced)),
                'retention_rate': float(total_retention),
                'deletion_rate': float(100 - total_retention),
                'train_quality': float(train_quality),
                'test_quality': float(test_quality),
                'test_quality_target_met': bool(test_target_met),
                'quantity_target_met': bool(quantity_target_met),
                'final_distribution': {str(k): int(v) for k, v in final_dist.to_dict().items()},
                'balance_ratio': float(max(final_dist) / min(final_dist)) if len(final_dist) >= 2 else 1.0
            },
            'class_details': {
                'train_stats': {str(k): {
                    'count': int(v['selected_count']),
                    'quality': float(v['average_quality'])
                } for k, v in train_stats.items()},
                'test_stats': {str(k): {
                    'count': int(v['selected_count']),
                    'quality': float(v['average_quality'])
                } for k, v in test_stats.items()}
            }
        }
        
        with open(f"{filtered_dataset_path}/dataset_info.json", 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, indent=2, ensure_ascii=False)
        
        print(f"   âœ… ä¿å­˜åˆ°: {filtered_dataset_path}/")
        print(f"   ğŸ“„ æ–‡ä»¶:")
        print(f"      - X_balanced_ultra.pkl (å¹³è¡¡è¶…é«˜è´¨é‡ç‰¹å¾æ•°æ®)")
        print(f"      - y_balanced_ultra.pkl (å¹³è¡¡è¶…é«˜è´¨é‡æ ‡ç­¾æ•°æ®)")
        print(f"      - dataset_info.json (è¯¦ç»†ç»Ÿè®¡)")
        
        # æœ€ç»ˆæ€»ç»“
        print(f"\nğŸ† æœ€ç»ˆæˆæœ:")
        if test_target_met and quantity_target_met:
            print(f"   âœ… å®Œç¾è¾¾æˆç›®æ ‡ï¼")
            print(f"   ğŸ“Š æµ‹è¯•é›†è´¨é‡: {test_quality*100:.1f}% (â‰¥90%)")
            print(f"   ğŸ“ˆ æ•°æ®é‡å……è¶³: {total_samples}ä¸ªæ ·æœ¬ (â‰¥500)")
            print(f"   âš–ï¸ ç±»åˆ«å¹³è¡¡: {balance_ratio:.1f}:1")
        else:
            print(f"   âš ï¸ éƒ¨åˆ†ç›®æ ‡è¾¾æˆ:")
            if test_target_met:
                print(f"   âœ… æµ‹è¯•é›†è´¨é‡è¾¾æ ‡: {test_quality*100:.1f}%")
            else:
                print(f"   âŒ æµ‹è¯•é›†è´¨é‡æœªè¾¾æ ‡: {test_quality*100:.1f}% < 90%")
            
            if quantity_target_met:
                print(f"   âœ… æ•°æ®é‡å……è¶³: {total_samples}ä¸ªæ ·æœ¬")
            else:
                print(f"   âŒ æ•°æ®é‡ä¸è¶³: {total_samples}ä¸ªæ ·æœ¬ < 500")
        
        print(f"\nğŸš€ ä½¿ç”¨æ–¹æ³•:")
        print(f"   X = pd.read_pickle('datasets/{filtered_dataset_name}/X_balanced_ultra.pkl')")
        print(f"   y = pd.read_pickle('datasets/{filtered_dataset_name}/y_balanced_ultra.pkl')")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    print("ğŸ¯ å¹³è¡¡ç‰ˆè¶…é«˜è´¨é‡rl_classæ•°æ®é›†ç”Ÿæˆå™¨")
    print("ğŸ”¥ ç›®æ ‡ï¼šè´¨é‡90%+ï¼Œæ•°é‡500+ï¼Œç±»åˆ«å¹³è¡¡")
    print("\nâš ï¸ åŸå§‹æ•°æ®ä¸ä¼šè¢«ä¿®æ”¹")
    
    # ç›´æ¥æ‰§è¡Œ
    create_balanced_ultra_high_quality_rl()


if __name__ == "__main__":
    main() 