"""
æ•°æ®è´¨é‡ç­›é€‰å™¨
åŸºäºPLSDAæ¨¡å‹çš„äº¤å‰éªŒè¯ç»“æœï¼Œç­›é€‰å‡ºé¢„æµ‹æ•ˆæœå¥½çš„æ ·æœ¬
ç›®æ ‡ï¼šæé«˜æ¨¡å‹æ€§èƒ½ï¼Œä¿æŒåŸå§‹æ•°æ®ä¸å˜
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score
from sklearn.cross_decomposition import PLSRegression
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')


class PLSDAForFiltering:
    """ç”¨äºæ•°æ®ç­›é€‰çš„PLSDAåˆ†ç±»å™¨"""
    
    def __init__(self, n_components=2):
        self.n_components = n_components
        self.pls = PLSRegression(n_components=n_components)
        self.label_encoder = LabelEncoder()
        
    def fit(self, X, y):
        """è®­ç»ƒæ¨¡å‹"""
        y_encoded = self.label_encoder.fit_transform(y)
        self.pls.fit(X, y_encoded)
        return self
    
    def predict(self, X):
        """é¢„æµ‹"""
        y_pred_continuous = self.pls.predict(X)
        y_pred_rounded = np.round(y_pred_continuous.flatten()).astype(int)
        y_pred_clipped = np.clip(y_pred_rounded, 0, len(self.label_encoder.classes_) - 1)
        return self.label_encoder.inverse_transform(y_pred_clipped)
    
    def predict_proba_like(self, X):
        """è·å–é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆæ¨¡æ‹Ÿæ¦‚ç‡ï¼‰"""
        y_pred_continuous = self.pls.predict(X).flatten()
        # å°†è¿ç»­é¢„æµ‹å€¼è½¬æ¢ä¸ºç½®ä¿¡åº¦åˆ†æ•°
        distances = np.abs(y_pred_continuous - np.round(y_pred_continuous))
        confidences = 1 - distances  # è·ç¦»æ•´æ•°è¶Šè¿‘ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        return confidences


class DataQualityFilter:
    """æ•°æ®è´¨é‡ç­›é€‰å™¨"""
    
    def __init__(self, cv_folds=5, n_components=10, random_state=42):
        self.cv_folds = cv_folds
        self.n_components = n_components
        self.random_state = random_state
        self.sample_scores_ = None
        self.feature_importance_ = None
        
    def _calculate_vip_scores(self, X, y):
        """è®¡ç®—VIPç‰¹å¾é‡è¦æ€§åˆ†æ•°"""
        print("   ğŸ” è®¡ç®—VIPç‰¹å¾é‡è¦æ€§...")
        
        # æ ‡å‡†åŒ–æ•°æ®
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # è®­ç»ƒPLSDAè·å–VIP
        max_components = min(self.n_components, X.shape[1], len(np.unique(y)))
        plsda = PLSDAForFiltering(n_components=max_components)
        plsda.fit(X_scaled, y)
        
        # è®¡ç®—VIPåˆ†æ•°
        W = plsda.pls.x_weights_
        Q = plsda.pls.y_loadings_
        
        ss_y = []
        for i in range(max_components):
            if Q.ndim == 1:
                ss_y_i = Q[i] ** 2 if i < len(Q) else 0
            else:
                ss_y_i = np.sum(Q[:, i] ** 2)
            ss_y.append(ss_y_i)
        
        total_ss_y = sum(ss_y)
        if total_ss_y == 0:
            return np.ones(X.shape[1])
        
        p = X.shape[1]
        vip_scores = np.zeros(p)
        
        for j in range(p):
            numerator = 0
            for i in range(max_components):
                numerator += (W[j, i] ** 2) * ss_y[i]
            vip_scores[j] = np.sqrt(p * numerator / total_ss_y)
        
        return vip_scores
    
    def _evaluate_sample_quality(self, X, y, feature_subset=None):
        """ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹è´¨é‡"""
        print("   ğŸ¯ è¯„ä¼°æ ·æœ¬é¢„æµ‹è´¨é‡...")
        
        if feature_subset is not None:
            X_subset = X.iloc[:, feature_subset] if hasattr(X, 'iloc') else X[:, feature_subset]
        else:
            X_subset = X
        
        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_subset)
        
        # äº¤å‰éªŒè¯è®¾ç½®
        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)
        
        # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„è¯„ä¼°ç»“æœ
        sample_correct_predictions = np.zeros(len(X_scaled))
        sample_confidences = np.zeros(len(X_scaled))
        sample_prediction_counts = np.zeros(len(X_scaled))
        
        # äº¤å‰éªŒè¯
        for fold, (train_idx, val_idx) in enumerate(cv.split(X_scaled, y)):
            print(f"      ğŸ“Š äº¤å‰éªŒè¯ {fold+1}/{self.cv_folds}")
            
            X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]
            y_train_fold, y_val_fold = y.iloc[train_idx] if hasattr(y, 'iloc') else y[train_idx], \
                                       y.iloc[val_idx] if hasattr(y, 'iloc') else y[val_idx]
            
            # è®­ç»ƒæ¨¡å‹
            max_components = min(self.n_components, X_train_fold.shape[1], len(np.unique(y_train_fold)))
            plsda = PLSDAForFiltering(n_components=max_components)
            plsda.fit(X_train_fold, y_train_fold)
            
            # é¢„æµ‹éªŒè¯é›†
            y_pred = plsda.predict(X_val_fold)
            confidences = plsda.predict_proba_like(X_val_fold)
            
            # è®°å½•é¢„æµ‹ç»“æœ
            correct_mask = (y_pred == y_val_fold.values if hasattr(y_val_fold, 'values') else y_pred == y_val_fold)
            sample_correct_predictions[val_idx] += correct_mask
            sample_confidences[val_idx] += confidences
            sample_prediction_counts[val_idx] += 1
        
        # è®¡ç®—æœ€ç»ˆåˆ†æ•°
        # å‡†ç¡®ç‡åˆ†æ•°ï¼ˆæ¯ä¸ªæ ·æœ¬è¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹ï¼‰
        accuracy_scores = sample_correct_predictions / np.maximum(sample_prediction_counts, 1)
        
        # å¹³å‡ç½®ä¿¡åº¦åˆ†æ•°
        confidence_scores = sample_confidences / np.maximum(sample_prediction_counts, 1)
        
        # ç»¼åˆè´¨é‡åˆ†æ•°ï¼ˆå‡†ç¡®ç‡ + ç½®ä¿¡åº¦ï¼‰
        quality_scores = 0.7 * accuracy_scores + 0.3 * confidence_scores
        
        return {
            'accuracy_scores': accuracy_scores,
            'confidence_scores': confidence_scores,
            'quality_scores': quality_scores,
            'prediction_counts': sample_prediction_counts
        }
    
    def fit(self, X, y, use_feature_selection=True, top_features_ratio=0.5):
        """
        è®­ç»ƒç­›é€‰å™¨ï¼Œè¯„ä¼°æ ·æœ¬è´¨é‡
        
        å‚æ•°:
        - X: ç‰¹å¾æ•°æ®
        - y: æ ‡ç­¾æ•°æ®  
        - use_feature_selection: æ˜¯å¦ä½¿ç”¨ç‰¹å¾é€‰æ‹©
        - top_features_ratio: ä½¿ç”¨å¤šå°‘æ¯”ä¾‹çš„é‡è¦ç‰¹å¾
        """
        print("ğŸ” å¼€å§‹æ•°æ®è´¨é‡è¯„ä¼°...")
        print(f"   ğŸ“Š æ•°æ®å½¢çŠ¶: {X.shape}")
        print(f"   ğŸ·ï¸ æ ‡ç­¾åˆ†å¸ƒ: {pd.Series(y).value_counts().to_dict()}")
        
        feature_subset = None
        
        if use_feature_selection and X.shape[1] > 10:
            # è®¡ç®—ç‰¹å¾é‡è¦æ€§
            vip_scores = self._calculate_vip_scores(X, y)
            self.feature_importance_ = pd.DataFrame({
                'feature_idx': range(len(vip_scores)),
                'feature_name': X.columns if hasattr(X, 'columns') else [f'feature_{i}' for i in range(X.shape[1])],
                'vip_score': vip_scores
            }).sort_values('vip_score', ascending=False)
            
            # é€‰æ‹©é‡è¦ç‰¹å¾
            n_top_features = max(5, int(X.shape[1] * top_features_ratio))
            feature_subset = self.feature_importance_.head(n_top_features)['feature_idx'].tolist()
            
            print(f"   âœ… ç‰¹å¾é€‰æ‹©: ä»{X.shape[1]}ä¸ªç‰¹å¾ä¸­é€‰æ‹©å‰{n_top_features}ä¸ª")
            print(f"   ğŸ” æœ€é‡è¦ç‰¹å¾: {self.feature_importance_.head(3)['feature_name'].tolist()}")
        
        # è¯„ä¼°æ ·æœ¬è´¨é‡
        sample_eval = self._evaluate_sample_quality(X, y, feature_subset)
        
        # å­˜å‚¨ç»“æœ
        self.sample_scores_ = pd.DataFrame({
            'sample_idx': range(len(X)),
            'accuracy_score': sample_eval['accuracy_scores'],
            'confidence_score': sample_eval['confidence_scores'], 
            'quality_score': sample_eval['quality_scores'],
            'prediction_count': sample_eval['prediction_counts']
        })
        
        print(f"   âœ… æ ·æœ¬è´¨é‡è¯„ä¼°å®Œæˆ")
        print(f"   ğŸ“ˆ è´¨é‡åˆ†æ•°èŒƒå›´: {self.sample_scores_['quality_score'].min():.4f} - {self.sample_scores_['quality_score'].max():.4f}")
        print(f"   ğŸ“Š å¹³å‡è´¨é‡åˆ†æ•°: {self.sample_scores_['quality_score'].mean():.4f}")
        
        return self
    
    def filter_samples(self, X, y, quality_threshold=None, keep_ratio=0.8, min_samples_per_class=10):
        """
        ç­›é€‰é«˜è´¨é‡æ ·æœ¬
        
        å‚æ•°:
        - X: ç‰¹å¾æ•°æ®
        - y: æ ‡ç­¾æ•°æ®
        - quality_threshold: è´¨é‡é˜ˆå€¼ï¼ŒNoneæ—¶è‡ªåŠ¨ç¡®å®š
        - keep_ratio: ä¿ç•™æ ·æœ¬çš„æ¯”ä¾‹
        - min_samples_per_class: æ¯ä¸ªç±»åˆ«æœ€å°‘ä¿ç•™çš„æ ·æœ¬æ•°
        """
        if self.sample_scores_ is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨fit()æ–¹æ³•è¯„ä¼°æ ·æœ¬è´¨é‡")
        
        print("ğŸ¯ å¼€å§‹ç­›é€‰é«˜è´¨é‡æ ·æœ¬...")
        
        # ç¡®å®šè´¨é‡é˜ˆå€¼
        if quality_threshold is None:
            # æ–¹æ³•1: æŒ‰æ¯”ä¾‹ä¿ç•™
            quality_threshold = self.sample_scores_['quality_score'].quantile(1 - keep_ratio)
        
        print(f"   ğŸ“ è´¨é‡é˜ˆå€¼: {quality_threshold:.4f}")
        
        # æŒ‰ç±»åˆ«ç­›é€‰ï¼Œç¡®ä¿æ¯ä¸ªç±»åˆ«éƒ½æœ‰è¶³å¤Ÿæ ·æœ¬
        y_series = pd.Series(y, index=range(len(y)))
        filtered_indices = []
        
        for class_label in y_series.unique():
            class_mask = (y_series == class_label)
            class_indices = y_series[class_mask].index.tolist()
            class_scores = self.sample_scores_.loc[class_indices]
            
            # ç¡®ä¿æ¯ä¸ªç±»åˆ«è‡³å°‘ä¿ç•™min_samples_per_classä¸ªæ ·æœ¬
            n_class_samples = len(class_indices)
            min_keep = min(min_samples_per_class, n_class_samples)
            
            # æŒ‰è´¨é‡åˆ†æ•°æ’åºï¼Œä¿ç•™é«˜è´¨é‡æ ·æœ¬
            class_scores_sorted = class_scores.sort_values('quality_score', ascending=False)
            
            # é¦–å…ˆä¿ç•™è¾¾åˆ°é˜ˆå€¼çš„æ ·æœ¬
            high_quality_mask = class_scores_sorted['quality_score'] >= quality_threshold
            high_quality_indices = class_scores_sorted[high_quality_mask]['sample_idx'].tolist()
            
            # å¦‚æœé«˜è´¨é‡æ ·æœ¬ä¸è¶³æœ€å°è¦æ±‚ï¼Œè¡¥å……æœ€å¥½çš„æ ·æœ¬
            if len(high_quality_indices) < min_keep:
                additional_needed = min_keep - len(high_quality_indices)
                remaining_indices = class_scores_sorted[~high_quality_mask]['sample_idx'].head(additional_needed).tolist()
                selected_indices = high_quality_indices + remaining_indices
            else:
                selected_indices = high_quality_indices
            
            filtered_indices.extend(selected_indices)
            
            print(f"   ğŸ“Š ç±»åˆ« {class_label}: {n_class_samples} -> {len(selected_indices)} æ ·æœ¬")
            print(f"      å¹³å‡è´¨é‡: {class_scores.loc[class_scores['sample_idx'].isin(selected_indices), 'quality_score'].mean():.4f}")
        
        # ç”Ÿæˆç­›é€‰åçš„æ•°æ®
        filtered_indices = sorted(filtered_indices)
        X_filtered = X.iloc[filtered_indices] if hasattr(X, 'iloc') else X[filtered_indices]
        y_filtered = y.iloc[filtered_indices] if hasattr(y, 'iloc') else y[filtered_indices]
        
        # é‡ç½®ç´¢å¼•
        if hasattr(X_filtered, 'reset_index'):
            X_filtered = X_filtered.reset_index(drop=True)
        if hasattr(y_filtered, 'reset_index'):
            y_filtered = y_filtered.reset_index(drop=True)
        
        print(f"   âœ… ç­›é€‰å®Œæˆ: {len(X)} -> {len(X_filtered)} æ ·æœ¬ ({len(X_filtered)/len(X)*100:.1f}%)")
        print(f"   ğŸ“ˆ ç­›é€‰åå¹³å‡è´¨é‡: {self.sample_scores_.loc[self.sample_scores_['sample_idx'].isin(filtered_indices), 'quality_score'].mean():.4f}")
        
        return X_filtered, y_filtered, filtered_indices
    
    def get_sample_scores(self):
        """è·å–æ ·æœ¬è´¨é‡åˆ†æ•°"""
        return self.sample_scores_
    
    def get_feature_importance(self):
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        return self.feature_importance_
    
    def save_quality_report(self, filepath, dataset_name):
        """ä¿å­˜è´¨é‡è¯„ä¼°æŠ¥å‘Š"""
        print(f"ğŸ’¾ ä¿å­˜è´¨é‡è¯„ä¼°æŠ¥å‘Š...")
        
        # æ ·æœ¬è´¨é‡ç»Ÿè®¡
        quality_stats = {
            'dataset_name': dataset_name,
            'total_samples': len(self.sample_scores_),
            'mean_quality': self.sample_scores_['quality_score'].mean(),
            'std_quality': self.sample_scores_['quality_score'].std(),
            'min_quality': self.sample_scores_['quality_score'].min(),
            'max_quality': self.sample_scores_['quality_score'].max(),
            'median_quality': self.sample_scores_['quality_score'].median(),
        }
        
        # è´¨é‡åˆ†å¸ƒ
        quality_bins = pd.cut(self.sample_scores_['quality_score'], bins=5, labels=['å¾ˆä½', 'ä½', 'ä¸­', 'é«˜', 'å¾ˆé«˜'])
        quality_distribution = quality_bins.value_counts().to_dict()
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report = {
            'summary': quality_stats,
            'quality_distribution': quality_distribution,
            'sample_scores': self.sample_scores_.to_dict('records')
        }
        
        if self.feature_importance_ is not None:
            report['feature_importance'] = self.feature_importance_.to_dict('records')
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        import json
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"   âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filepath}")
        return report 