"""
LLMå¤„ç†å™¨æ¨¡å—
è´Ÿè´£ä¸OpenAI APIçš„äº¤äº’å’Œæ¨èç”Ÿæˆ
"""

import logging
from typing import List, Dict, Any, Optional
import openai
from openai import OpenAI

logger = logging.getLogger(__name__)


class LLMHandler:
    """LLMå¤„ç†å™¨ï¼Œè´Ÿè´£ä¸OpenAI APIäº¤äº’"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–LLMå¤„ç†å™¨
        
        Args:
            api_key: OpenAI APIå¯†é’¥
        """
        self.api_key = api_key
        self.client = None
        if api_key:
            self.set_api_key(api_key)
    
    def set_api_key(self, api_key: str) -> bool:
        """
        è®¾ç½®APIå¯†é’¥ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        
        Args:
            api_key: OpenAI APIå¯†é’¥
            
        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        return self.set_api_config({
            'api_key': api_key,
            'api_base': 'https://api.openai.com/v1',
            'model': 'gpt-3.5-turbo'
        })
    
    def set_api_config(self, config: dict) -> bool:
        """
        è®¾ç½®APIé…ç½®
        
        Args:
            config: åŒ…å«api_key, api_base, modelçš„é…ç½®å­—å…¸
            
        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        try:
            self.api_key = config['api_key']
            self.api_base = config['api_base']
            self.model = config['model']
            
            # å¤„ç†APIåœ°å€
            if self.api_base.endswith('/v1'):
                base_url = self.api_base
            else:
                base_url = self.api_base.rstrip('/') + '/v1'
            
            # åˆ›å»ºå®¢æˆ·ç«¯
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=base_url
            )
            
            # æµ‹è¯•APIè¿æ¥
            test_response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "ä½ å¥½"}],
                max_tokens=10,
                timeout=10
            )
            
            logger.info(f"AIæœåŠ¡è¿æ¥æˆåŠŸ - æ¨¡å‹: {self.model}")
            return True
            
        except Exception as e:
            logger.error(f"è®¾ç½®AIé…ç½®å¤±è´¥: {e}")
            self.client = None
            return False
    
    def is_api_ready(self) -> bool:
        """
        æ£€æŸ¥APIæ˜¯å¦å°±ç»ª
        
        Returns:
            APIæ˜¯å¦å°±ç»ª
        """
        return self.client is not None
    
    def chat_with_recommendations(self, 
                                user_message: str,
                                recommendations: Dict[str, Any] = None,
                                conversation_history: List[Dict[str, str]] = None) -> str:
        """
        åŸºäºæ¨èç»“æœä¸ç”¨æˆ·èŠå¤©
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            recommendations: RAGæ¨èç»“æœ
            conversation_history: å¯¹è¯å†å²
            
        Returns:
            AIå›å¤
        """
        if not self.is_api_ready():
            return "âŒ AI service not configured, please configure AI service first."
        
        try:
            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = self._build_system_prompt()
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": system_prompt}]
            
            # æ·»åŠ å¯¹è¯å†å²
            if conversation_history:
                messages.extend(conversation_history[-10:])  # ä¿ç•™æœ€è¿‘10æ¡å¯¹è¯
            
            # æ·»åŠ æ¨èä¿¡æ¯åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸­
            enhanced_message = self._enhance_user_message(user_message, recommendations)
            messages.append({"role": "user", "content": enhanced_message})
            
            # è°ƒç”¨AI API
            model_name = getattr(self, 'model', 'gpt-3.5-turbo')
            response = self.client.chat.completions.create(
                model=model_name,
                messages=messages,
                temperature=0.1
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {e}")
            return f"âŒ Error occurred while generating response: {str(e)}"
    
    def generate_recommendation_summary(self, recommendations: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ¨èæ‘˜è¦
        
        Args:
            recommendations: æ¨èç»“æœ
            
        Returns:
            æ¨èæ‘˜è¦æ–‡æœ¬
        """
        if not self.is_api_ready():
            return "API not configured, unable to generate recommendation summary."
        
        try:
            # æ„å»ºæ¨èæ•°æ®å­—ç¬¦ä¸²
            rec_text = self._format_recommendations_for_prompt(recommendations)
            
            prompt = f"""
            Based on the following MXLLM material recommendation data, generate a concise English summary:
            
            {rec_text}
            
            Please provide:
            1. Recommended chemical formulas and their characteristics
            2. Recommended synthesis processes and their advantages
            3. Recommended testing methods and their applications
            4. Overall suggestions and precautions
            
            Requirements: Use concise professional language, emphasize practicality. Do not use markdown format, use plain text format.
            """
            
            model_name = getattr(self, 'model', 'gpt-3.5-turbo')
            response = self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¨èæ‘˜è¦å¤±è´¥: {e}")
            return f"Error occurred while generating recommendation summary: {str(e)}"
    
    def analyze_user_query(self, query: str) -> Dict[str, Any]:
        """
        åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œæå–å…³é”®ä¿¡æ¯
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            åˆ†æç»“æœ
        """
        if not self.is_api_ready():
            return {"intent": "unknown", "keywords": [], "requirements": []}
        
        try:
            prompt = f"""
            åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œæå–å…³é”®ä¿¡æ¯ï¼š
            
            æŸ¥è¯¢: "{query}"
            
            è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
            {{
                "intent": "æŸ¥è¯¢æ„å›¾ï¼ˆå¦‚ï¼šå¯»æ‰¾åŒ–å­¦å¼ã€åˆæˆæ–¹æ³•ã€æµ‹è¯•æµç¨‹ã€ç»¼åˆå’¨è¯¢ç­‰ï¼‰",
                "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...],
                "requirements": ["éœ€æ±‚1", "éœ€æ±‚2", ...],
                "application": "åº”ç”¨åœºæ™¯ï¼ˆå¦‚ï¼šå¸æ³¢ææ–™ã€ç”µç£å±è”½ç­‰ï¼‰"
            }}
            """
            
            model_name = getattr(self, 'model', 'gpt-3.5-turbo')
            response = self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            
            # å°è¯•è§£æJSONå“åº”
            import json
            try:
                result = json.loads(response.choices[0].message.content.strip())
                return result
            except json.JSONDecodeError:
                return {
                    "intent": "general_inquiry",
                    "keywords": [query],
                    "requirements": [],
                    "application": "æœªæŒ‡å®š"
                }
                
        except Exception as e:
            logger.error(f"åˆ†æç”¨æˆ·æŸ¥è¯¢å¤±è´¥: {e}")
            return {
                "intent": "unknown",
                "keywords": [query],
                "requirements": [],
                "application": "æœªçŸ¥"
            }
    
    def translate_to_professional_english(self, query_text: str) -> str:
        """
        å°†æŸ¥è¯¢è½¬æ¢æˆ–æ¶¦è‰²ä¸ºä¸“ä¸šè‹±æ–‡
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¯ä»¥æ˜¯ä¸­æ–‡æˆ–è‹±æ–‡ï¼‰
            
        Returns:
            ä¸“ä¸šè‹±æ–‡æŸ¥è¯¢
        """
        if not self.is_api_ready():
            return query_text
        
        try:
            prompt = f"""
Please translate and polish the following query into a professional English material science term:

Query: "{query_text}"

Requirements:
1. If it's Chinese, please translate it to English
2. If it's already English, please polish it into a more professional term
3. Use standard material science professional terms
4. Professional term equivalents:
   - "Heterostructure" â†’ "heterostructure"
   - "Composite" â†’ "composite"
   - "Electromagnetic wave absorption materials" â†’ "electromagnetic wave absorption materials"
   - "Nanomaterials" â†’ "nanomaterials"
5. Ensure academic accuracy of terms
6. Only return the final professional English query, do not add any other content

Professional English query:"""

            # æ‰“å°ç¿»è¯‘å¹¶æ¶¦è‰²promptä¿¡æ¯
            logger.info("=" * 60)
            logger.info("ğŸŒâœ¨ Translation and Polishing PROMPT Details:")
            logger.info("=" * 60)
            logger.info(f"ğŸ” Original Query: {query_text}")
            logger.info("ğŸ“‹ Full Prompt:")
            logger.info("-" * 30)
            logger.info(prompt)
            logger.info("-" * 30)

            model_name = getattr(self, 'model', 'gpt-3.5-turbo')
            logger.info(f"ğŸ¤– Using model: {model_name}")
            logger.info(f"ğŸ”§ Parameters: max_tokens=100, temperature=0.1")
            
            response = self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            
            # è·å–å’Œå¤„ç†å“åº”
            raw_response = response.choices[0].message.content.strip()
            logger.info("ğŸ¤– Translation and Polishing Response:")
            logger.info(f"ğŸ“„ Raw Response: '{raw_response}'")
            
            english_query = raw_response
            # æ¸…ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
            english_query = english_query.replace('"', '').replace('Professional English query:', '').replace('English query:', '').strip()
            
            if english_query != raw_response:
                logger.info(f"ğŸ§¹ Cleaned response: '{english_query}'")
            
            logger.info(f"âœ… Translation and Polishing completed: {query_text} â†’ {english_query}")
            logger.info("=" * 60)
            
            return english_query
            
        except Exception as e:
            logger.error("âŒ Translation and Polishing failed:")
            logger.error(f"Error details: {e}")
            logger.error("=" * 60)
            return query_text

    def analyze_and_extract_recommendations(self, query: str, context_text: str) -> Dict[str, Any]:
        """
        åˆ†ææœç´¢ç»“æœå¹¶æå–ç»“æ„åŒ–æ¨è
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context_text: æœç´¢åˆ°çš„æ–‡æ¡£ä¸Šä¸‹æ–‡
            
        Returns:
            åŒ…å«åŒ–å­¦å¼ã€åˆæˆå·¥è‰ºã€æµ‹è¯•æµç¨‹çš„ç»“æ„åŒ–å­—å…¸
        """
        if not self.is_api_ready():
            return {
                "chemical_formulas": [],
                "synthesis_methods": [],
                "testing_procedures": [],
                "error": "LLM service not configured"
            }
        
        try:
            prompt = f"""
You are a rigorous materials science research assistant. Based on the "Search Results" below and user query "{query}", select and recommend **only 1 best material**, and output **verified, verifiable** multi-step synthesis and testing protocols.

ã€Strict Rules | Must Followã€‘
1) No speculation or padding: Only write **content you are certain is real**; do not output placeholders (like "N/A", "unknown", empty strings, 0).
2) No units means no entry: If the original text doesn't provide **values or units** for an item, **don't write that key**; don't add or estimate on your own.
3) Multi-step: Both synthesis and testing should be written step-by-step in **steps arrays** (each object = one step). If literature has multiple steps, increase accordingly; if you think there are **important steps not mentioned in original text** (like necessary washing/drying/mounting/calibration), **allow supplementing as "inferred steps"**:
   - "Inferred steps" must not contain specific values/units not given;
   - Must add `"inferred": true` and `"justification"` (brief rationale, like "standard process essential step/industry practice").
4) Precursors: If precursors exist, must include an independent step with `role: "precursor"`.
5) Recommend only 1 material: Only 1 material entry; briefly explain selection rationale in `rationale` (based on original text evidence).
6) For heterostructure queries, only select heterostructure materials.
7) Output **only a valid JSON object**, no additional text; all strings use **double quotes**.

ã€Search Resultsã€‘
{context_text}

ã€Output JSON Structureã€‘(Keys may be omitted; except `material.chemical_formula` is required, other fields omit if no reliable information)
{{
  "source": "Source literature title",
  "doi": "DOI number",
  "query": "{query}",
  "content": [
    {{
      "record_designation": "Sample/formula identifier (if given in original text)",
      "material": {{
        "chemical_formula": "Specific chemical formula (required, e.g. Ti3C2Tx or explicit composite/heterostructure)",
        "name": "Material name/common name (if any)",
        "composition_type": "Single/doped/composite/heterostructure (if any)",
        "structure_type": "Crystal/layered/porous/core-shell/interface type (if any)",
        "morphology": "Morphology (if any)",
        "heterostructure_type": "Heterostructure type (if any)"
      }},
      "performance": {{
        "rl_min": "e.g. \"-50.06 dB\" (if available, retain original units with necessary conditions inline)",
        "matching_thickness": "e.g. \"1.5 mm\" (if available)",
        "eab": "e.g. \"4.0 GHz\" (if available)",
        "other": "Other key performance points mentioned in original text (if any, brief)"
      }},
      "synthesis_steps": [
        {{
          "step": 1,
          "role": "precursor",
          "step_name": "Step name (prioritize original text terminology)",
          "method": "Method/process name (if any)",
          "inputs": ["Raw materials/solvents/additives/precursors (if any)"],
          "conditions": ["Write key conditions as **string entries** one by one; omit this key if none"],
          "outputs": "Intermediates/morphology/structural features obtained in this step (if any)",
          "notes": "Safety/filtering/washing/drying etc. (if any)"
        }}
        /* Can continue adding steps 2, 3...; for "inferred steps", need to add:
           "inferred": true,
           "justification": "Why this step is standard and necessary (no values/units)"
        */
      ],
      "testing_steps": [
        {{
          "step": 1,
          "step_name": "Sample pretreatment/mounting/measurement etc. (prioritize original text terminology)",
          "method": "Testing method/instrument paradigm (if any)",
          "parameters": ["Write key parameters as **string entries**; omit this key if none"],
          "notes": "Such as baseline/calibration/repetition times and other original text points (if any)"
        }}
        /* Same as above, list step by step; can include "inferred steps" (need to mark inferred and justification, no values/units) */
      ],
      "confidence": "high/medium/low"
    }}
  ]
}}
"""

            # æ‰“å°å®Œæ•´çš„promptä¿¡æ¯
            logger.info("=" * 80)
            logger.info("ï¿½ï¿½ AI PROMPT Details:")
            logger.info("=" * 80)
            logger.info(f"ğŸ” Query: {query}")
            logger.info(f"ğŸ“ Context Length: {len(context_text)} characters")
            logger.info("ğŸ“‹ Full Prompt:")
            logger.info("-" * 40)
            logger.info(prompt)
            logger.info("-" * 40)

            model_name = getattr(self, 'model', 'gpt-3.5-turbo')
            logger.info(f"ğŸ¤– Using model: {model_name}")
            
            response = self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            
            # è·å–åŸå§‹å“åº”
            raw_response = response.choices[0].message.content.strip()
            logger.info("=" * 80)
            logger.info("ğŸ¤– AI Response Details:")
            logger.info("=" * 80)
            logger.info(f"ğŸ“„ Raw Response Length: {len(raw_response)} characters")
            logger.info("ğŸ“‹ Full Response:")
            logger.info("-" * 40)
            logger.info(raw_response)
            logger.info("-" * 40)
            
            # æ¸…ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
            clean_response = self._clean_json_response(raw_response)
            
            if clean_response != raw_response:
                logger.info("ğŸ§¹ Cleaned response:")
                logger.info("-" * 40)
                logger.info(clean_response)
                logger.info("-" * 40)
            
            # è§£æJSONå“åº”
            import json
            try:
                result = json.loads(clean_response)
                logger.info("âœ… JSON parsed successfully")
                logger.info(f"ğŸ“Š Returned results: {len(result.get('chemical_formulas', []))} chemical formulas, "
                           f"{len(result.get('synthesis_methods', []))} synthesis methods, "
                           f"{len(result.get('testing_procedures', []))} testing procedures")
                logger.info("=" * 80)
                return result
            except json.JSONDecodeError as e:
                logger.error("âŒ JSON parsing failed details:")
                logger.error(f"Error: {e}")
                logger.error(f"Error position: Line {e.lineno}, Column {e.colno}")
                logger.error(f"Cleaned response first 500 characters: {clean_response[:500]}...")
                
                # å°è¯•æ‰‹åŠ¨ä¿®å¤å¸¸è§JSONé—®é¢˜
                fixed_response = self._try_fix_json(clean_response)
                if fixed_response:
                    try:
                        result = json.loads(fixed_response)
                        logger.info("âœ… JSON fixed successfully")
                        logger.info("=" * 80)
                        return result
                    except:
                        logger.error("âŒ JSON fixing also failed")
                
                logger.info("=" * 80)
                return {
                    "chemical_formulas": [],
                    "synthesis_methods": [],
                    "testing_procedures": [],
                    "error": "LLM returned incorrect format",
                    "raw_response": raw_response[:200] + "..." if len(raw_response) > 200 else raw_response
                }
                
        except Exception as e:
            logger.error("âŒ LLM call failed:")
            logger.error(f"Error details: {e}")
            logger.error("=" * 80)
            return {
                "chemical_formulas": [],
                "synthesis_methods": [],
                "testing_procedures": [],
                "error": f"LLM analysis error: {str(e)}"
            }
    
    def _build_system_prompt(self) -> str:
        """
        æ„å»ºç³»ç»Ÿæç¤º
        
        Returns:
            ç³»ç»Ÿæç¤ºæ–‡æœ¬
        """
        return """
        You are a professional MXLLM material research assistant, specializing in helping users with MXLLM electromagnetic wave absorption material research and development.

        Your responsibilities:
        1. Recommend appropriate chemical formulas, synthesis processes, and testing procedures based on provided literature data
        2. Answer professional questions about MXLLM materials
        3. Provide practical research suggestions and technical guidance
        4. Explain the relationship between material properties and application scenarios

        Response requirements:
        - Answer in English
        - Use professional but understandable language
        - Provide specific actionable suggestions
        - **When citing recommendation data, must include corresponding DOI numbers to ensure literature traceability**
        - Format DOI information when recommending chemical formulas, synthesis processes, or testing procedures
        - Emphasize practicality and feasibility
        - Do not use markdown formatting like **

        CRITICAL: When users inquire, you MUST prioritize answering based on the specific recommendation data provided in the user message. 
        If recommendation data is provided, base your entire response on that data and cite the specific sources, DOI numbers, and experimental details mentioned.
        Only use general knowledge if explicitly noted that no database recommendations are available.
        If recommendation data includes DOI numbers, please clearly display them in your answer, format as:
        - Chemical Formula: Ti3C2Tx (DOI: 10.xxxx/xxxx)
        - Synthesis Method: HF Etching (DOI: 10.xxxx/xxxx)
        
        Always check if the user message contains "Relevant recommendations retrieved from database" - if it does, focus your response on analyzing and explaining those specific recommendations rather than providing general information.
        """
    
    def _enhance_user_message(self, user_message: str, recommendations: Dict[str, Any] = None) -> str:
        """
        å¢å¼ºç”¨æˆ·æ¶ˆæ¯ï¼Œæ·»åŠ æ¨èä¿¡æ¯
        
        Args:
            user_message: ç”¨æˆ·åŸå§‹æ¶ˆæ¯
            recommendations: æ¨èç»“æœ
            
        Returns:
            å¢å¼ºåçš„æ¶ˆæ¯
        """
        if not recommendations:
            # æ²¡æœ‰æ¨èæ•°æ®æ—¶ï¼Œç›´æ¥è¿”å›ç”¨æˆ·æ¶ˆæ¯
            return f"User query: {user_message}\n\nNote: Currently in quick mode, unable to provide database-based recommendations, please answer based on general knowledge."
        
        # æ£€æŸ¥æ–°æ ¼å¼çš„æ•°æ®ç»“æ„ (åŒ…å«contenté”®)
        if recommendations.get('content') and isinstance(recommendations['content'], list) and len(recommendations['content']) > 0:
            enhanced = f"User query: {user_message}\n\n"
            enhanced += "Relevant recommendations retrieved from database:\n"
            enhanced += self._format_recommendations_for_prompt(recommendations)
            return enhanced
        
        # æ£€æŸ¥æ—§æ ¼å¼çš„æ•°æ®ç»“æ„
        if any(recommendations.get(key, []) for key in ['chemical_formulas', 'synthesis_methods', 'testing_procedures']):
            enhanced = f"User query: {user_message}\n\n"
            enhanced += "Relevant recommendations retrieved from database:\n"
            enhanced += self._format_recommendations_for_prompt(recommendations)
        return enhanced
        
        # å¦‚æœæ¨èæ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨å¿«é€Ÿæ¨¡å¼æç¤º
        return f"User query: {user_message}\n\nNote: Currently in quick mode, unable to provide database-based recommendations, please answer based on general knowledge."
    
    def _format_recommendations_for_prompt(self, recommendations: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–æ¨èç»“æœç”¨äºæç¤º
        
        Args:
            recommendations: æ¨èç»“æœ
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        formatted = ""
        
        def format_value(value):
            """é€šç”¨å€¼æ ¼å¼åŒ–å‡½æ•°ï¼Œå¤„ç†å„ç§æ•°æ®ç±»å‹"""
            if isinstance(value, dict):
                # å­—å…¸ç±»å‹ï¼šå°è¯•æå–å…³é”®ä¿¡æ¯
                if 'name' in value:
                    # å¦‚æœæœ‰nameå­—æ®µï¼Œä¼˜å…ˆä½¿ç”¨name
                    result = value['name']
                    if 'amount' in value:
                        result += f" ({value['amount']})"
                    elif 'volume' in value:
                        result += f" ({value['volume']})"
                    return result
                else:
                    # å¦åˆ™è½¬æ¢ä¸ºkey: valueæ ¼å¼
                    pairs = [f"{k}: {v}" for k, v in value.items()]
                    return "; ".join(pairs)
            elif isinstance(value, list):
                # åˆ—è¡¨ç±»å‹ï¼šé€’å½’å¤„ç†æ¯ä¸ªå…ƒç´ 
                return ", ".join([format_value(item) for item in value])
            else:
                # å…¶ä»–ç±»å‹ç›´æ¥è½¬å­—ç¬¦ä¸²
                return str(value)
        
        # æ£€æŸ¥æ–°æ ¼å¼çš„æ•°æ®ç»“æ„ (åŒ…å«contenté”®)
        if recommendations.get('content') and isinstance(recommendations['content'], list):
            content = recommendations['content']
            source = recommendations.get('source', 'Unknown source')
            doi = recommendations.get('doi', '')
            
            formatted += f"Data source: {source}\n"
            if doi:
                formatted += f"DOI: {doi}\n"
            formatted += "\n"
            
            for i, item in enumerate(content, 1):
                material = item.get('material', {})
                performance = item.get('performance', {})
                synthesis_steps = item.get('synthesis_steps', [])
                testing_steps = item.get('testing_steps', [])
                confidence = item.get('confidence', 'medium')
                
                formula = material.get('chemical_formula', 'Unknown')
                formatted += f"Material {i}: {formula} (Confidence: {confidence})\n"
                
                # ææ–™ä¿¡æ¯
                if material.get('composition_type'):
                    formatted += f"  Composition type: {material['composition_type']}\n"
                if material.get('structure_type'):
                    formatted += f"  Structure type: {material['structure_type']}\n"
                if material.get('morphology'):
                    formatted += f"  Morphology: {material['morphology']}\n"
                
                # æ€§èƒ½æ•°æ®
                if performance:
                    formatted += "  Performance data:\n"
                    for key, value in performance.items():
                        if value and value != "":
                            display_name = {
                                'rl_min': 'RL Minimum',
                                'matching_thickness': 'Matching Thickness',
                                'eab': 'Effective Absorption Bandwidth',
                                'other': 'Other Performance'
                            }.get(key, key)
                            formatted += f"    {display_name}: {format_value(value)}\n"
                
                # åˆæˆæ­¥éª¤
                if synthesis_steps:
                    formatted += "  Synthesis steps:\n"
                    for step in synthesis_steps:
                        step_name = step.get('step_name', 'Unknown step')
                        method = step.get('method', '')
                        formatted += f"    {step.get('step', 0)}. {step_name}"
                        if method:
                            formatted += f" ({method})"
                        formatted += "\n"
                        
                        if step.get('inputs'):
                            inputs = step['inputs']
                            formatted += f"       Inputs: {format_value(inputs)}\n"
                        
                        if step.get('conditions'):
                            conditions = step['conditions']
                            formatted += f"       Conditions: {format_value(conditions)}\n"
                        
                        if step.get('outputs'):
                            outputs = step['outputs']
                            formatted += f"       Outputs: {format_value(outputs)}\n"
                        
                        if step.get('notes'):
                            notes = step['notes']
                            formatted += f"       Notes: {format_value(notes)}\n"
                
                # æµ‹è¯•æ­¥éª¤
                if testing_steps:
                    formatted += "  Testing steps:\n"
                    for step in testing_steps:
                        step_name = step.get('step_name', 'Unknown step')
                        method = step.get('method', '')
                        formatted += f"    {step.get('step', 0)}. {step_name}"
                        if method:
                            formatted += f" ({method})"
                        formatted += "\n"
                        
                        if step.get('parameters'):
                            parameters = step['parameters']
                            formatted += f"       Parameters: {format_value(parameters)}\n"
                        
                        if step.get('notes'):
                            notes = step['notes']
                            formatted += f"       Notes: {format_value(notes)}\n"
                
                formatted += "\n"
            
            return formatted
        
        # å¤„ç†æ—§æ ¼å¼çš„æ•°æ®ç»“æ„ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        # åŒ–å­¦å¼æ¨è
        if recommendations.get('chemical_formulas'):
            formatted += "Recommended chemical formulas:\n"
            for i, formula in enumerate(recommendations['chemical_formulas'], 1):
                formatted += f"{i}. {formula.get('formula', 'Unknown')}\n"
                formatted += f"   Source: {formula.get('source', 'Unknown')}\n"
                if formula.get('doi'):
                    formatted += f"   DOI: {formula['doi']}\n"
                formatted += f"   Relevance: {formula.get('score', 0):.2f}\n"
                
                # æ·»åŠ éªŒè¯å’Œæ€§èƒ½ä¿¡æ¯
                if formula.get('validation'):
                    validation = formula['validation']
                    formatted += f"   Performance validation: {formula.get('performance_summary', 'Unknown')}\n"
                    
                    if validation['found_in_db']:
                        # å®éªŒæ•°æ®
                        exp_data = validation['experimental_data']
                        if exp_data and len(exp_data) > 0:
                            first_data = exp_data[0]
                            formatted += f"   Experimental performance: "
                            if first_data.get('properties'):
                                props = first_data['properties']
                                prop_strs = [f"{k}={v}" for k, v in props.items()]
                                formatted += ", ".join(prop_strs)
                            formatted += "\n"
                            if first_data.get('doi'):
                                formatted += f"   Performance data DOI: {first_data['doi']}\n"
                    
                    elif validation.get('prediction'):
                        # é¢„æµ‹æ•°æ®
                        pred = validation['prediction']
                        formatted += f"   AI predicted performance: EAB={pred['eab_prediction']}({pred['eab_meaning']}), RL={pred['rl_prediction']}({pred['rl_meaning']})\n"
                        formatted += f"   Prediction confidence: {pred['confidence']:.2f}\n"
                
                if formula.get('description'):
                    formatted += f"   Description: {formula['description']}\n"
                formatted += "\n"
        
        # åˆæˆå·¥è‰ºæ¨è
        if recommendations.get('synthesis_methods'):
            formatted += "Recommended synthesis processes:\n"
            for i, method in enumerate(recommendations['synthesis_methods'], 1):
                formatted += f"{i}. {method.get('method', 'Unknown')}\n"
                formatted += f"   Source: {method.get('source', 'Unknown')}\n"
                if method.get('doi'):
                    formatted += f"   DOI: {method['doi']}\n"
                formatted += f"   Relevance: {method.get('score', 0):.2f}\n"
                if method.get('description'):
                    formatted += f"   Description: {method['description']}\n"
                formatted += "\n"
        
        # æµ‹è¯•æµç¨‹æ¨è
        if recommendations.get('testing_procedures'):
            formatted += "Recommended testing procedures:\n"
            for i, procedure in enumerate(recommendations['testing_procedures'], 1):
                formatted += f"{i}. {procedure.get('procedure', 'Unknown')}\n"
                formatted += f"   Source: {procedure.get('source', 'Unknown')}\n"
                if procedure.get('doi'):
                    formatted += f"   DOI: {procedure['doi']}\n"
                formatted += f"   Relevance: {procedure.get('score', 0):.2f}\n"
                if procedure.get('description'):
                    formatted += f"   Description: {procedure['description']}\n"
                formatted += "\n"
        
        return formatted
    
    def format_chat_response(self, 
                           ai_response: str, 
                           recommendations: Dict[str, Any] = None) -> str:
        """
        æ ¼å¼åŒ–èŠå¤©å›å¤ï¼ŒåŒ…å«æ¨èä¿¡æ¯
        
        Args:
            ai_response: AIå›å¤
            recommendations: æ¨èç»“æœ
            
        Returns:
            æ ¼å¼åŒ–åçš„å›å¤
        """
        formatted_response = ai_response
        
        if recommendations:
            formatted_response += "\n\n" + "="*50 + "\n"
            formatted_response += "ğŸ“‹ **Database-based recommendation results**\n\n"
            
            # æ£€æŸ¥æ–°æ ¼å¼çš„æ•°æ®ç»“æ„
            if recommendations.get('content') and isinstance(recommendations['content'], list):
                # æ–°çš„JSONæ ¼å¼
                content = recommendations['content']
                source = recommendations.get('source', 'Unknown source')
                doi = recommendations.get('doi', '')
                
                formatted_response += f"ï¿½ï¿½ **Data source:** {source}\n"
                if doi:
                    formatted_response += f"ï¿½ï¿½ **DOI:** {doi}\n"
                formatted_response += "\n"
                
                for i, item in enumerate(content, 1):
                    material = item.get('material', {})
                    performance = item.get('performance', {})
                    confidence = item.get('confidence', 'medium')
                    
                    formula = material.get('chemical_formula', 'Unknown')
                    confidence_text = {'high': 'High', 'medium': 'Medium', 'low': 'Low'}.get(confidence, confidence)
                    
                    formatted_response += f"ğŸ§ª **Material {i}: {formula}** (Confidence: {confidence_text})\n"
                    
                    # ææ–™ç‰¹æ€§
                    if material.get('composition_type'):
                        formatted_response += f"   â€¢ Composition type: {material['composition_type']}\n"
                    if material.get('structure_type'):
                        formatted_response += f"   â€¢ Structure type: {material['structure_type']}\n"
                    if material.get('morphology'):
                        formatted_response += f"   â€¢ Morphology: {material['morphology']}\n"
                    
                    # æ€§èƒ½æ•°æ®
                    if performance:
                        formatted_response += "   ï¿½ï¿½ **Performance data:**\n"
                        for key, value in performance.items():
                            if value and value != "":
                                display_name = {
                                    'rl_min': 'RL Minimum',
                                    'matching_thickness': 'Matching Thickness',
                                    'eab': 'Effective Absorption Bandwidth',
                                    'other': 'Other Performance'
                                }.get(key, key)
                                formatted_response += f"     - {display_name}: {value}\n"
                    
                    # åˆæˆæ­¥éª¤
                    synthesis_steps = item.get('synthesis_steps', [])
                    if synthesis_steps:
                        formatted_response += "   âš—ï¸ **Synthesis steps:**\n"
                        for step in synthesis_steps:
                            step_name = step.get('step_name', 'Unknown step')
                            method = step.get('method', '')
                            formatted_response += f"     {step.get('step', 0)}. {step_name}"
                            if method:
                                formatted_response += f" ({method})"
                            formatted_response += "\n"
                    
                    # æµ‹è¯•æ­¥éª¤
                    testing_steps = item.get('testing_steps', [])
                    if testing_steps:
                        formatted_response += "   ï¿½ï¿½ **Testing steps:**\n"
                        for step in testing_steps:
                            step_name = step.get('step_name', 'Unknown step')
                            method = step.get('method', '')
                            formatted_response += f"     {step.get('step', 0)}. {step_name}"
                            if method:
                                formatted_response += f" ({method})"
                            formatted_response += "\n"
                    
                    formatted_response += "\n"
            else:
                # å…¼å®¹æ—§æ ¼å¼
                # æ·»åŠ åŒ–å­¦å¼æ¨è
                if recommendations.get('chemical_formulas'):
                    formatted_response += "ğŸ§ª **Recommended chemical formulas:**\n"
                    for i, formula in enumerate(recommendations['chemical_formulas'], 1):
                        formatted_response += f"{i}. **{formula.get('formula', 'Unknown')}**\n"
                        formatted_response += f"   ğŸ“– Source: {formula.get('source', 'Unknown')}\n"
                        formatted_response += f"   ğŸ¯ Relevance: {formula.get('score', 0):.1%}\n\n"
                
                # æ·»åŠ åˆæˆå·¥è‰ºæ¨è
                if recommendations.get('synthesis_methods'):
                    formatted_response += "âš—ï¸ **Recommended synthesis processes:**\n"
                    for i, method in enumerate(recommendations['synthesis_methods'], 1):
                        formatted_response += f"{i}. **{method.get('method', 'Unknown')}**\n"
                        formatted_response += f"   ğŸ“– Source: {method.get('source', 'Unknown')}\n"
                        formatted_response += f"   ï¿½ï¿½ Relevance: {method.get('score', 0):.1%}\n\n"
                
                # æ·»åŠ æµ‹è¯•æµç¨‹æ¨è
                if recommendations.get('testing_procedures'):
                    formatted_response += "ğŸ”¬ **Recommended testing procedures:**\n"
                    for i, procedure in enumerate(recommendations['testing_procedures'], 1):
                        formatted_response += f"{i}. **{procedure.get('procedure', 'Unknown')}**\n"
                        formatted_response += f"   ï¿½ï¿½ Source: {procedure.get('source', 'Unknown')}\n"
                        formatted_response += f"   ğŸ¯ Relevance: {procedure.get('score', 0):.1%}\n\n"
        
        return formatted_response 

    def _clean_json_response(self, response: str) -> str:
        """æ¸…ç†JSONå“åº”ä¸­çš„å¸¸è§é—®é¢˜"""
        # ç§»é™¤å¯èƒ½çš„å‰åç¼€
        response = response.strip()
        
        # æ‰¾åˆ°JSONçš„å¼€å§‹å’Œç»“æŸ
        start_idx = response.find('{')
        end_idx = response.rfind('}')
        
        if start_idx != -1 and end_idx != -1:
            response = response[start_idx:end_idx+1]
        
        # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
        response = response.replace('```json', '').replace('```', '')
        
        return response.strip()
    
    def _try_fix_json(self, json_str: str) -> str:
        """å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜"""
        try:
            # ä¿®å¤å¸¸è§çš„å¼•å·é—®é¢˜
            import re
            
            # ç¡®ä¿å±æ€§åéƒ½æœ‰åŒå¼•å·
            json_str = re.sub(r'([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', json_str)
            
            # ä¿®å¤å°¾éšé€—å·
            json_str = re.sub(r',\s*}', '}', json_str)
            json_str = re.sub(r',\s*]', ']', json_str)
            
            return json_str
        except:
            return None 